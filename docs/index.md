# Driver Identification Using Deep LSTM Network

While driving on your way to work, you come across a lot of other road users. More often than not, you can judge the way people drive from an outside perspective. Are they sticking to the right lane behind the trucks while going 80 km/h on the freeway, or are they that tail-gating german luxury car driver that really needs to pass you, even though you're already doing 20 km/h over the speedlimit? Considering that we as humans already can have somewhat of an indication of the driving style of people by simply sharing the road with them, what could a computer then achieve when it has access to the multitude of sensors available in a modern car? 

Automatically identifying the user of a car based on their driving style would come with a plethora of applications. It could for example be used to check if the owner of the car is the one actually driving which then could be used for theft prevention. Another possibility is to use this data for more specialised insurance plans, or one could image it to be used to judge the driving styles of people within a shared fleet of cars. 

Before we can look into these applications, first we need to know if it is even possible to correctly identify the current driver of a car. To test this, Girma, Yan and Homaifar have come up with a Deep LSTM based method of identifying drivers based on their driving style. In this blog we test their model by building our own implementation of it from scratch. We will take a look at the implementation they used, and see if it is as robust as they have claimed in the paper by performing comparable experiments to them. 

## The Data
Modern cars are all equiped with an On-Board Diagnostics (OBD) connector. OBD is a standard that has been implemented to make most diagnostic information available without the need for manufacturer specific hardware to have access to it. Via this connection, one can directly read most sensor output from the car. Which sensors are actually available still can depend on the make and model of the car, but most cars have a set of standard sensors. The paper uses two different datasets to test their model. One of these, the dataset used to test the model in this blog, is a set of 51 sensors, including, but not limited to: steering wheel input, engine RPMs, throttle input, car speed and fuel consumption. For a full list of sensors used, please see the extras section at the bottom of the page. 

The data used in this research was generated by having ten different people make a round trip, and recording the sensor data from these drives. The data was then labeled based on the driver. This results in a set of timeseries data containing timesteps with 51 features each. 

## Why an LSTM?
A Long Short-Term Memory network, or LSTM for short, is a specialized form of neural networks. Like convolutional network is highly speciales for 2D image data, an LSTM is highly specialed for time series data. 

Since the sensor data is all collected with a set time interval, one sample after the other holds some interdependance and is order dependent. To illustrate the interdependance of the samples, consider the following example: When taking two consecutive samples, a car driving 10 km/h for the first sample and 0 km/h for the second sample probably came to a slow stop, while a car driving 50 km/h for the first sample and 0 km/h for the second sample had to do an emergency stop. The order for these samples then also has influence over the interpretation, as a car going from 50 to 0 is braking, while a car going from 0 to 50 is accelerating.

An LSTM is specifically designed to work with these properties of the data. Predictions made by the network are not only based on the current input, but also on a combination of a certain amount of previous inputs. Hence the name Long Short-Term Memory, as it remembers what has come before.

## Preparing the Data
In order to train the LSTM, the data must first prepared. As with most AI applications, in order to make the non-linearities of a neural network function properly, the inputs should be normalized to fit in a range of 0 to 1. 

After normalization, the data must be prepared for use within the LSTM. Since the LSTM depends on the history for an input to make its prediction, the samples fed to it during training should also have this history included. A single sample in this case would then consist of the input sample, along with a set amount of history input samples. This is done by applying a sliding window function across the input data as described in the figure below. 

//TODO: add figure

With N being the total amount of samples and H being the size of the sliding window, this would then result in an input data size of shape [N, H, 51] as we have 51 features for each timestep. The labels for these samples are then encoded as a one-hot vector of length 10, as we have ten different drivers in the dataset.

## Building the model
Now that the data has been prepared, it is time to take a closer look at the model itself. The model conists of three different layers, of which two LSTM layers and one standard fully connected layer. The fully connected layer here uses a sigmoid activation function and is used to translate the output of the LSTM layers to a 10 length output vector, containing the probabilities for each driver based on the presented sample. The driver with the highest score in this vector is considered to be the chosen prediction.

The LSTM layers do the bulk of the work. The first layer has a hidden size of 160 and acts as the input layer for the network. This means that the input size of this layer should be adapted to the window size chosen during data preperation. The second layer conists of 200 hidden units and works directly on the outputs of the first layer. Because of this, it is important that the first layer also returns sequences. Using Keras as a deeplearning library, an implementation of this network would look something like this

```python
from tensorflow.keras import Sequential
from tensorflow.keras.layers import LSTM, Dense

model = Sequential()
model.add(LSTM(160, input_shape=(window_size, num_features), return_sequences=True ))
model.add(LSTM(200, ))

model.add(Dense(10, activation="sigmoid"))
```

## Our results


## Comparing to authors code
 - authors limited to 21 features?
 -  

## Extras
// TODO: add full list of features in dataset?

